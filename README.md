# Autonomous-Maze-Solving-Robot-
This project features an autonomous robot designed to solve mazes by reading signs on the walls and navigating to the end goal. The robot leverages machine vision algorithms, machine learning for sign recognition, and advanced path planning and search algorithms to efficiently navigate complex environments.

Georgia Institute of Technology: Team 21: Sagar Desai and Eemil Harkonen 

## Demo


[![Watch the demo](https://img.youtube.com/vi/VIDEO_ID/0.jpg)](https://youtu.be/6Tk9iepP2Z4)



Led the development of the machine vision subsystem responsible for detecting and interpreting signs on maze walls. Designed and implemented computer vision algorithms using OpenCV for robust image processing under variable lighting conditions. Developed machine learning models to accurately classify and read different sign types, enabling the robot to make context-aware navigation decisions. Integrated real-time video input with the control system to provide continuous environmental feedback. Collaborated on optimizing the vision pipeline for low-latency performance essential to autonomous operation. This work directly supported the robotâ€™s path planning by supplying reliable environmental cues for dynamic route adjustments. Eemil led the development of the motion control and navigation system, implementing dead reckoning techniques to enable precise robot localization within the maze. He designed algorithms to estimate position based on wheel encoder data and inertial measurements, ensuring accurate movement tracking despite environmental uncertainties. His work integrated closely with the machine vision system to adjust paths dynamically and reach the end goal efficiently. 
